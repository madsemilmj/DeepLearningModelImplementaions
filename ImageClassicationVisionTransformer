# Image Classification with Vision Transformer

Transformer architecture is being highly evaluated by its efficiency and scalability, which has made it possible
to train models of unprecedented scale, with over 100B parameters (i.e., GPT-3). Also it is regarded as defacto standard of NLP tasks. Nowadays, conglomerates like Google is trying hard to push Transformer's
limit towards vision tasks. ViT is a monumental model which has successfully adapted Transformer to vision tasks (i.e., image classification). Specifically, ViT regards an image as 1616 words (tokens), and processes
it through consecutive Transformer encoder layers.
In this notebook, I am going to implement the training process of ViT (https://arxiv.org/abs/2103.15691)
model, using the CIFAR-10 dataset.
